{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     object\n",
      "1     object\n",
      "2     object\n",
      "3     object\n",
      "4     object\n",
      "       ...  \n",
      "60    object\n",
      "61    object\n",
      "62    object\n",
      "63    object\n",
      "64    object\n",
      "Length: 65, dtype: object\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "60    0\n",
      "61    0\n",
      "62    0\n",
      "63    0\n",
      "64    0\n",
      "Length: 65, dtype: int64\n",
      "Colonne 'Target' ignorée pour la conversion.\n",
      "Target         object\n",
      "Features1     float64\n",
      "Features2     float64\n",
      "Features3     float64\n",
      "Features4     float64\n",
      "               ...   \n",
      "Features60    float64\n",
      "Features61    float64\n",
      "Features62    float64\n",
      "Features63    float64\n",
      "Features64    float64\n",
      "Length: 65, dtype: object\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "csv_filename = \"cubes_info.csv\"\n",
    "data = pd.read_csv(csv_filename, header=None, sep=';')  \n",
    "print(data.dtypes)\n",
    "print(data.isna().sum())\n",
    "\n",
    "data.rename(columns={data.columns[0]: 'Target'}, inplace=True)\n",
    "for i in range(1 , len(data.columns)):\n",
    "    data.rename(columns={data.columns[i]: f'Features{i}'}, inplace=True)\n",
    "\n",
    "\n",
    "for col in data.columns:\n",
    "    if col != 'Target':  \n",
    "        if data[col].dtype == 'object':\n",
    "            try:\n",
    "                data[col] = data[col].apply(lambda x: float(x.split(',')[2]))  # Extraire la pente (slope)\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur lors de la conversion de la colonne {col}: {e}\")\n",
    "    else:\n",
    "        print(f\"Colonne 'Target' ignorée pour la conversion.\")\n",
    "\n",
    "\n",
    "print(data.dtypes)\n",
    "\n",
    "X = data.drop(columns=('Target') , axis=1)\n",
    "Y = data['Target']\n",
    "scaler = StandardScaler()\n",
    "X_scaled =  scaler.fit_transform(X)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 64)\n",
      "['b' 'f' 'g' 'h' 'j' 'k']\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print((Y.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Meilleurs paramètres : {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (128, 64, 32), 'learning_rate': 'constant', 'max_iter': 500, 'solver': 'adam'}\n",
      "\n",
      "Rapport de classification :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.84      0.89      0.86        18\n",
      "    Classe 1       0.94      1.00      0.97        15\n",
      "    Classe 2       1.00      0.81      0.90        16\n",
      "    Classe 3       0.44      0.64      0.52        11\n",
      "    Classe 4       0.93      1.00      0.96        13\n",
      "    Classe 5       0.83      0.59      0.69        17\n",
      "\n",
      "    accuracy                           0.82        90\n",
      "   macro avg       0.83      0.82      0.82        90\n",
      "weighted avg       0.85      0.82      0.83        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64,), (64, 32), (128, 64, 32)], \n",
    "    'activation': ['relu', 'tanh'],  \n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],  \n",
    "    'alpha': [0.0001, 0.001], \n",
    "    'learning_rate': ['constant', 'adaptive'],  \n",
    "    'max_iter': [500, 1000, 1500] \n",
    "}\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(random_state=2021)\n",
    "\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=5, scoring='f1_macro', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Meilleurs paramètres : {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"/nRapport de classification :/n\", classification_report(y_test, y_pred, target_names=[f\"Classe {i}\" for i in range(6)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Classe 0       0.81      0.94      0.87        18\n",
      "    Classe 1       0.93      0.87      0.90        15\n",
      "    Classe 2       1.00      0.94      0.97        16\n",
      "    Classe 3       0.57      0.73      0.64        11\n",
      "    Classe 4       0.93      1.00      0.96        13\n",
      "    Classe 5       0.92      0.65      0.76        17\n",
      "\n",
      "    accuracy                           0.86        90\n",
      "   macro avg       0.86      0.85      0.85        90\n",
      "weighted avg       0.87      0.86      0.86        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(32,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "train_score = mlp.score(X_train, y_train)\n",
    "test_score = mlp.score(X_test, y_test)\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=[f\"Classe {i}\" for i in range(6)])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_score': 1.0, 'test_score': 0.82, 'classification_report': {'Classe 0': {'precision': 0.8421052631578947, 'recall': 0.8888888888888888, 'f1-score': 0.8648648648648649, 'support': 18.0}, 'Classe 1': {'precision': 0.9375, 'recall': 1.0, 'f1-score': 0.967741935483871, 'support': 15.0}, 'Classe 2': {'precision': 1.0, 'recall': 0.8125, 'f1-score': 0.896551724137931, 'support': 16.0}, 'Classe 3': {'precision': 0.4375, 'recall': 0.6363636363636364, 'f1-score': 0.5185185185185185, 'support': 11.0}, 'Classe 4': {'precision': 0.9285714285714286, 'recall': 1.0, 'f1-score': 0.9629629629629629, 'support': 13.0}, 'Classe 5': {'precision': 0.8333333333333334, 'recall': 0.5882352941176471, 'f1-score': 0.6896551724137931, 'support': 17.0}, 'accuracy': 0.8222222222222222, 'macro avg': {'precision': 0.8298350041771094, 'recall': 0.8209979698950286, 'f1-score': 0.816715863063657, 'support': 90.0}, 'weighted avg': {'precision': 0.8474554441659704, 'recall': 0.8222222222222222, 'f1-score': 0.8263876037698804, 'support': 90.0}}}\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "metrics = {\n",
    "    \"train_score\": round(best_model.score(X_train, y_train),2),\n",
    "    \"test_score\":round(best_model.score(X_test, y_test),2),\n",
    "    \"classification_report\": classification_report(y_test, y_pred, target_names=[f\"Classe {i}\" for i in range(6)], output_dict=True),\n",
    "}\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pkl'\n"
     ]
    }
   ],
   "source": [
    "with open(\"best_mlp_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(\"model\": best_model, file)\n",
    "\n",
    "print(\"model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur : Le fichier .pkl n'existe pas au chemin spécifié.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "try:\n",
    "    with open(\"C:/Users/huetb/Desktop/Cours/Bachelor 3/Projet Lettre ML/code/final/projetml 1/test_model.pkl\", \"rb\") as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "    \n",
    "    print(f\"Clés disponibles : {loaded_object.keys()}\")\n",
    "    \n",
    "    model = loaded_object[\"model\"]\n",
    "    print(f\"Modèle chargé : {type(model)}\")\n",
    "    \n",
    "    # Test d'une prédiction si les données sont disponibles\n",
    "    # test_data = ...  # Remplacez par vos données de test\n",
    "    # prediction = model.predict(test_data)\n",
    "    # print(f\"Prédiction : {prediction}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Erreur : Le fichier .pkl n'existe pas au chemin spécifié.\")\n",
    "except KeyError as e:\n",
    "    print(f\"Erreur : Clé manquante dans le fichier .pkl ({e}).\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur inattendue : {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
